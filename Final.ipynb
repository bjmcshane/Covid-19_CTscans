{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brendan/opt/anaconda3/envs/firstEnv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/brendan/opt/anaconda3/envs/firstEnv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/brendan/opt/anaconda3/envs/firstEnv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/brendan/opt/anaconda3/envs/firstEnv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/brendan/opt/anaconda3/envs/firstEnv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/brendan/opt/anaconda3/envs/firstEnv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 28)\n"
     ]
    }
   ],
   "source": [
    "# reading in our labels\n",
    "# also has data on other details of the patience but we just want to look at an image and\n",
    "# an output for right now\n",
    "metadata = pd.read_csv('metadata.csv').to_numpy()\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "print(metadata.shape)\n",
    "\n",
    "i=0\n",
    "for row in metadata:\n",
    "    # row[20] is the folder and row[21] is the filename\n",
    "    filename = row[20] + '/' + row[21]\n",
    "    \n",
    "    if filename[-3:] == '.gz': # ignoring gunzipped files, not that many of them and dealing with it would vastly complicate things\n",
    "        i+=1\n",
    "    else:\n",
    "        img = Image.open(filename)\n",
    "        \n",
    "        if filename[-3:] == 'png':\n",
    "            img = img.convert('RGB') #converting png to jpg\n",
    "            \n",
    "        img = img.convert('LA')  # grayscaling\n",
    "        img = img.resize((156,156)) # resizing to minimums so every image is the same size\n",
    "        data = asarray(img) # transforming image to array of ints\n",
    "        X.append(data)\n",
    "        \n",
    "        if row[4] == 'COVID-19':\n",
    "            y.append((1,0))\n",
    "        else:\n",
    "            y.append((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/brendan/opt/anaconda3/envs/firstEnv/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# building our model (finally)\n",
    "\n",
    "inputShape = X[0].shape\n",
    "BATCH_SIZE=32 # ended up not going with this because it took an extremely long time to train\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, \n",
    "                 kernel_size=(3,3), \n",
    "                 input_shape=(156,156,2), \n",
    "                 activation= 'relu',\n",
    "                 data_format='channels_last'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation= 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "#model.fit(np.array(X), np.array(y), batch_size=BATCH_SIZE, validation_split=0.1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 243 samples, validate on 28 samples\n",
      "243/243 [==============================] - 17s 69ms/sample - loss: 3.4963 - acc: 0.7819 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "68/68 [==============================] - 1s 17ms/sample - loss: 5.4220 - acc: 0.6618\n",
      "Train on 243 samples, validate on 28 samples\n",
      "243/243 [==============================] - 19s 77ms/sample - loss: 4.8816 - acc: 0.6955 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "68/68 [==============================] - 1s 19ms/sample - loss: 0.4715 - acc: 0.9706\n",
      "Train on 243 samples, validate on 28 samples\n",
      "243/243 [==============================] - 16s 67ms/sample - loss: 2.5728 - acc: 0.8395 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "68/68 [==============================] - 1s 17ms/sample - loss: 8.7223 - acc: 0.4559\n",
      "Train on 243 samples, validate on 28 samples\n",
      "243/243 [==============================] - 15s 61ms/sample - loss: 4.5518 - acc: 0.7160 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "68/68 [==============================] - 1s 17ms/sample - loss: 1.6502 - acc: 0.8971\n",
      "Train on 244 samples, validate on 28 samples\n",
      "244/244 [==============================] - 15s 63ms/sample - loss: 4.3360 - acc: 0.7295 - val_loss: 1.7175 - val_acc: 0.8929\n",
      "67/67 [==============================] - 1s 17ms/sample - loss: 1.6748 - acc: 0.8955\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "#actual_outputs = [] I was going to do a mse of the end results but figured using the\n",
    "#my_predictions = [] binary cross entropy I set up earlier would be simpler and more effective\n",
    "result_loss = []\n",
    "result_acc = []\n",
    "\n",
    "i=1\n",
    "for train, test in kf.split(X):\n",
    "    X_train = np.array(X)[train]\n",
    "    y_train = np.array(y)[train]\n",
    "    X_test = np.array(X)[test]\n",
    "    y_test = np.array(y)[test]\n",
    "    \n",
    "    model.fit(X_train, y_train, batch_size=BATCH_SIZE, validation_split=0.1, epochs=1)\n",
    "    \n",
    "    loss, acc = model.evaluate(X_test, y_test)\n",
    "    result_loss.append(loss)\n",
    "    result_acc.append(acc)\n",
    "    \n",
    "    #pred = model.predict(X_test)\n",
    "    #actual_outputs.append(y_test)\n",
    "    #my_predictions.append(pred)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg loss: 3.588155827406726\n",
      "avg accuracy: 0.7761632978916169\n"
     ]
    }
   ],
   "source": [
    "# and here are our results\n",
    "#print('losses: ' + result_loss)\n",
    "print('avg loss: ' + str(sum(result_loss)/5))\n",
    "#print('accuracies: ' + result_acc)\n",
    "print('avg accuracy: ' + str(sum(result_acc)/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this project I decided to build a machine learning model that learned how to \n",
    "# diagnose coronavirus from CT scans of people with and without the virus. It shook down to your\n",
    "# typical image processing model, each sample being classified as either 0-not infected, or \n",
    "# 1-infected. I found a dataset on github (https://github.com/ieee8023/covid-chestxray-dataset)\n",
    "# and used the metadata.csv file to prep the expected labels. There's additional information\n",
    "# in there, but the amount of time it'd take to get useful results out of that info didn't\n",
    "# make using it appealing\n",
    "\n",
    "# For the model itself I used a convolutional neural network. It was essentially comprised of\n",
    "# two conv2D + maxpooling2D layers. The convolitional layers slide a window over the matrix of\n",
    "# pixels and records the data, and the maxpooling layers reduce the dimensionality of the images\n",
    "# essentially by reducing the number of pixels we're looking at. I used cross-fold validation\n",
    "# to get more bang for my buck because I was working with a relatively smallish dataset.\n",
    "\n",
    "# the resulting average accuracy from the 5 folds was 77.62%, which all in all isn't terrible\n",
    "# but isn't winning me any nobel peace prizes anytime soon. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
